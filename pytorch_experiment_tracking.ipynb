{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw7L0NI/CgaCOE6URjlfSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torrhen/pytorch/blob/main/pytorch_experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u5h1Mg8jSpb",
        "outputId": "19e1134f-1caa-4a3b-95ee-07f193cc1677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1109270528 bytes == 0x377dc000 @  0x7f5756233615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.13.1-cp38-cp38-manylinux1_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.0+cu116\n",
            "    Uninstalling torchaudio-0.13.0+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1\n",
            "torch version: 1.13.0+cu116\n",
            "torchvision version: 0.14.0+cu116\n"
          ]
        }
      ],
      "source": [
        "# import torch and torchvision libraries\n",
        "try:\n",
        "  import torch\n",
        "  import torchvision\n",
        "  assert(torch.__version__.split(\".\")[1] >= 12)\n",
        "  assert(torchvision.__version__.split(\".\")[1] >= 13)\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")\n",
        "# install torch and torchvision libraries if necessary\n",
        "except:\n",
        "  !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  import torch\n",
        "  import torchvision\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# import torchinfo summary\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "# install torchinfo summary if necessary\n",
        "except:\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# import third party scripts\n",
        "try:\n",
        "  from going_modular.going_modular import data_setup, engine\n",
        "# clone github scripts if necessary\n",
        "except:\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRjjgFb30w5P",
        "outputId": "3cbcdb4a-4f41-4e32-bdbd-e5f4c430af8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 3369, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 3369 (delta 25), reused 49 (delta 23), pack-reused 3302\u001b[K\n",
            "Receiving objects: 100% (3369/3369), 641.24 MiB | 31.44 MiB/s, done.\n",
            "Resolving deltas: 100% (1932/1932), done.\n",
            "Checking out files: 100% (221/221), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "JKhYkdbH1mvn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the random seed\n",
        "def set_seed(seed: int = 42):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "u-SFSewE2IF6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# create folder paths\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# check if images folder already exists\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} already exists\")\n",
        "else:\n",
        "  # create image folder\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  # download the training and test image zip folder from GitHub\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    response = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    f.write(response.content)\n",
        "  # extract images zip folder\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as z:\n",
        "    z.extractall(image_path)\n",
        "  # remove images zip folder after extraction\n",
        "  os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "id": "xRpor1dLBfsl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the file paths of the training and test images\n",
        "train_folder = image_path / \"train\"\n",
        "test_folder = image_path / \"test\""
      ],
      "metadata": {
        "id": "X8gKjwj3D93v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the weights of the pretrained model\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "# store the transforms used to obtain the weights\n",
        "auto_transform = weights.transforms()\n",
        "\n",
        "# divide the training and test data into batches\n",
        "train_loader, test_loader, class_names = data_setup.create_dataloaders(train_dir=train_folder,\n",
        "                                                                   test_dir = test_folder,\n",
        "                                                                   transform=auto_transform,\n",
        "                                                                   batch_size=32)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwS3p4KDEJZW",
        "outputId": "1a86f1d5-ecff-4881-c9c5-748af1a39895"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model using pretrained weights\n",
        "model_0 = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# freeze the weights of the features component of the model\n",
        "for param in model_0.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# set random seed\n",
        "set_seed()\n",
        "\n",
        "# modify the classifier of the model to accomodate the classes of data\n",
        "model_0.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "iR9J7Z72HhLL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# display architecture of the model\n",
        "summary(model_0, input_size=(32, 3, 224, 244), col_names=['input_size', 'output_size', 'trainable'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ORVXFFJTM2",
        "outputId": "e374b821-f24f-49e1-fc20-8cd9ad090b9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==================================================================================================================================\n",
              "Layer (type:depth-idx)                                  Input Shape               Output Shape              Trainable\n",
              "==================================================================================================================================\n",
              "EfficientNet                                            [32, 3, 224, 244]         [32, 3]                   Partial\n",
              "├─Sequential: 1-1                                       [32, 3, 224, 244]         [32, 1280, 7, 8]          False\n",
              "│    └─Conv2dNormActivation: 2-1                        [32, 3, 224, 244]         [32, 32, 112, 122]        False\n",
              "│    │    └─Conv2d: 3-1                                 [32, 3, 224, 244]         [32, 32, 112, 122]        False\n",
              "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 122]        [32, 32, 112, 122]        False\n",
              "│    │    └─SiLU: 3-3                                   [32, 32, 112, 122]        [32, 32, 112, 122]        --\n",
              "│    └─Sequential: 2-2                                  [32, 32, 112, 122]        [32, 16, 112, 122]        False\n",
              "│    │    └─MBConv: 3-4                                 [32, 32, 112, 122]        [32, 16, 112, 122]        False\n",
              "│    └─Sequential: 2-3                                  [32, 16, 112, 122]        [32, 24, 56, 61]          False\n",
              "│    │    └─MBConv: 3-5                                 [32, 16, 112, 122]        [32, 24, 56, 61]          False\n",
              "│    │    └─MBConv: 3-6                                 [32, 24, 56, 61]          [32, 24, 56, 61]          False\n",
              "│    └─Sequential: 2-4                                  [32, 24, 56, 61]          [32, 40, 28, 31]          False\n",
              "│    │    └─MBConv: 3-7                                 [32, 24, 56, 61]          [32, 40, 28, 31]          False\n",
              "│    │    └─MBConv: 3-8                                 [32, 40, 28, 31]          [32, 40, 28, 31]          False\n",
              "│    └─Sequential: 2-5                                  [32, 40, 28, 31]          [32, 80, 14, 16]          False\n",
              "│    │    └─MBConv: 3-9                                 [32, 40, 28, 31]          [32, 80, 14, 16]          False\n",
              "│    │    └─MBConv: 3-10                                [32, 80, 14, 16]          [32, 80, 14, 16]          False\n",
              "│    │    └─MBConv: 3-11                                [32, 80, 14, 16]          [32, 80, 14, 16]          False\n",
              "│    └─Sequential: 2-6                                  [32, 80, 14, 16]          [32, 112, 14, 16]         False\n",
              "│    │    └─MBConv: 3-12                                [32, 80, 14, 16]          [32, 112, 14, 16]         False\n",
              "│    │    └─MBConv: 3-13                                [32, 112, 14, 16]         [32, 112, 14, 16]         False\n",
              "│    │    └─MBConv: 3-14                                [32, 112, 14, 16]         [32, 112, 14, 16]         False\n",
              "│    └─Sequential: 2-7                                  [32, 112, 14, 16]         [32, 192, 7, 8]           False\n",
              "│    │    └─MBConv: 3-15                                [32, 112, 14, 16]         [32, 192, 7, 8]           False\n",
              "│    │    └─MBConv: 3-16                                [32, 192, 7, 8]           [32, 192, 7, 8]           False\n",
              "│    │    └─MBConv: 3-17                                [32, 192, 7, 8]           [32, 192, 7, 8]           False\n",
              "│    │    └─MBConv: 3-18                                [32, 192, 7, 8]           [32, 192, 7, 8]           False\n",
              "│    └─Sequential: 2-8                                  [32, 192, 7, 8]           [32, 320, 7, 8]           False\n",
              "│    │    └─MBConv: 3-19                                [32, 192, 7, 8]           [32, 320, 7, 8]           False\n",
              "│    └─Conv2dNormActivation: 2-9                        [32, 320, 7, 8]           [32, 1280, 7, 8]          False\n",
              "│    │    └─Conv2d: 3-20                                [32, 320, 7, 8]           [32, 1280, 7, 8]          False\n",
              "│    │    └─BatchNorm2d: 3-21                           [32, 1280, 7, 8]          [32, 1280, 7, 8]          False\n",
              "│    │    └─SiLU: 3-22                                  [32, 1280, 7, 8]          [32, 1280, 7, 8]          --\n",
              "├─AdaptiveAvgPool2d: 1-2                                [32, 1280, 7, 8]          [32, 1280, 1, 1]          --\n",
              "├─Sequential: 1-3                                       [32, 1280]                [32, 3]                   True\n",
              "│    └─Dropout: 2-10                                    [32, 1280]                [32, 1280]                --\n",
              "│    └─Linear: 2-11                                     [32, 1280]                [32, 3]                   True\n",
              "==================================================================================================================================\n",
              "Total params: 4,011,391\n",
              "Trainable params: 3,843\n",
              "Non-trainable params: 4,007,548\n",
              "Total mult-adds (G): 13.87\n",
              "==================================================================================================================================\n",
              "Input size (MB): 20.99\n",
              "Forward/backward pass size (MB): 3821.27\n",
              "Params size (MB): 16.05\n",
              "Estimated Total Size (MB): 3858.31\n",
              "=================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiE586XdJTHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}